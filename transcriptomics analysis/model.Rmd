---
title: "Model"
author: "Roshan Shafiha"
output: html_document
keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(dev = "png",
                      dpi = 300,
                      echo = TRUE,
                      cache = TRUE)
```

## R Markdown

Objective:

GSE151158,GSE58979,GSE63067,GSE89632 are merged and split into training and testing data for the random forest.With these dataset the parameters for the random forest were tuned.GSM836223 is used for validating the model. 

## Loading the library and dataset



```{r}

library(randomForest)
library(caret)
library(e1071)
library(alookr)
library(dplyr)
library(pROC)
library(ggplot2)
library(ggpubr)
library(ggsignif)
library(enrichR)
library(DT)
library(corrplot)
library(dplyr)
library(tibble)
```

load the data 

```{r }

data<-read.csv("dataset_model.csv",header = T,row.names = 1)

validation<-read.csv("validation.csv",header = T,row.names = 1)



data_scaled<-scale(data[,2:ncol(data)])

data_scaled<-as.data.frame(data_scaled)

data_scaled<-add_column(data_scaled, sample=data$sample, .before = 1)

data<-data_scaled

#write.csv(data,"significant_genes.csv")

head(data)
summary(data)

validation_scaled<-scale(validation[,2:ncol(validation)])

validation_scaled<-as.data.frame(validation_scaled)

validation_scaled<-add_column(validation_scaled, sample=validation$sample, .before = 1)

validation<-validation_scaled

head(validation)
summary(validation)

```

lets split the dataset

```{r}

sb <- data %>%
  split_by(sample, seed = 6534)

attr_names <- names(attributes(sb))

sb_attr <- attributes(sb)

```

observe how the target category is separated


```{r}

sb %>%
  compare_target_category()

```


plot the sample 

```{r}

sb %>%
  compare_plot("sample")

```


compare the variables in the train and test set 

```{r}

sb %>%
  compare_target_numeric()

```

Extract the train and test dataset


```{r}
train <- sb %>%
  extract_set(set = "train")

test <- sb %>%
  extract_set(set = "test")

```


## Random Forest

set up the control .

In this case the repeated 10 cross validation approach is applied which gets repeated for 5 times 

```{r}

trControl <- trainControl(method = "repeatedcv",
                          number = 10,
                          repeats = 5,
                          search = "grid",
                          summaryFunction=twoClassSummary,
                          classProbs=TRUE,
                          savePredictions = T)

```

build the model with default values initially and observe the results

```{r}
set.seed(1234)

#Run the model

rf_default <- train(sample~.,
                    data = train,
                    method = "rf",
                    metric = "ROC",
                    trControl = trControl)
# Print the results

print(rf_default)
```


Now lets extract the best mtry

```{r}

set.seed(1234)

tuneGrid <- expand.grid(.mtry = c(1: 15))

rf_mtry <- train(sample~.,
                 data = train,
                 method = "rf",
                 metric = "ROC",
                 tuneGrid = tuneGrid,
                 trControl = trControl,
                 importance = TRUE,
                 nodesize = 14,
                 ntree = 50)
print(rf_mtry)

plot(rf_mtry)

#store the mtry to compare it with the other variable which we are going to 

best_mtry <- rf_mtry$bestTune$mtry 

print(best_mtry)

```

next lets train the maxnodes 

```{r}

set.seed(1234)

store_maxnode <- list()
tuneGrid <- expand.grid(.mtry = best_mtry)
for (maxnodes in c(5:15)) {
  set.seed(1234)
  rf_maxnode <- train(sample~.,
                      data = train,
                      method = "rf",
                      metric = "ROC",
                      tuneGrid = tuneGrid,
                      trControl = trControl,
                      importance = TRUE,
                      nodesize = 14,
                      maxnodes = maxnodes,
                      ntree = 50)
  current_iteration <- toString(maxnodes)
  store_maxnode[[current_iteration]] <- rf_maxnode
}
results_mtry <- resamples(store_maxnode)

summary(results_mtry)

```


lets try increasing the node and see if there is any change.


```{r}

set.seed(1234)

store_maxnode <- list()
tuneGrid <- expand.grid(.mtry = best_mtry)
for (maxnodes in c(20: 30)) {
  set.seed(1234)
  rf_maxnode <- train(sample~.,
                      data = train,
                      method = "rf",
                      metric = "ROC",
                      tuneGrid = tuneGrid,
                      trControl = trControl,
                      importance = TRUE,
                      nodesize = 14,
                      maxnodes = maxnodes,
                      ntree = 50)
  key <- toString(maxnodes)
  store_maxnode[[key]] <- rf_maxnode
}
results_node <- resamples(store_maxnode)

summary(results_node)

```

extract the best number of trees and identify the best features for the random forest.

```{r}
set.seed(1234)

store_maxtrees <- list()
for (ntree in c(10,15,20,25,30,35,40,45,50,55,100,150,200,250, 300,350,400)) {
  set.seed(5678)
  rf_maxtrees <- train(sample~.,
                       data = train,
                       method = "rf",
                       metric = "ROC",
                       tuneGrid = tuneGrid,
                       trControl = trControl,
                       importance = TRUE,
                       nodesize = 14,
                       maxnodes = 5,
                       ntree = ntree)
  key <- toString(ntree)
  store_maxtrees[[key]] <- rf_maxtrees
}

results_tree <- resamples(store_maxtrees)

summary(results_tree)

```


extract the best number of trees and identify the best features for the random forest.


```{r}
set.seed(1234)

fit_rf <- train(sample~.,
                data= train,
                method = "rf",
                metric = "ROC",
                tuneGrid = tuneGrid,
                trControl = trControl,
                importance = TRUE,
                nodesize = 14,
                ntree = 55,
                maxnodes = 6)

print(fit_rf$bestTune)

res<-fit_rf$results

```


Make predictions using the test data set


```{r,message = TRUE}

probs_test <- predict(fit_rf,test,type="prob")

test$sample = as.factor(test$sample)

gbm.ROC_test<- roc(predictor=probs_test$steatosis,
                  response=test$sample)

table(test$sample)

print(gbm.ROC_test[["auc"]])

```


Repeat the steps for the validation set


```{r,message = TRUE}


probs_val <- predict(fit_rf,validation,type="prob")

validation$sample=as.factor(validation$sample)

gbm.ROC_val<- roc(predictor=probs_val$steatosis,
               response=validation$sample)

table(validation$sample)

print(gbm.ROC_val[["auc"]])

print(colnames(validation))


```


plot the ROC curve 

```{r}
plot(gbm.ROC_test,col ="darkred",main="Random Forest ROC curve",
     col.lab="black", cex.lab=1.5)
text(x = 0.7445764,y =0.8701577,label="AUC:0.91",cex=1)

plot(gbm.ROC_val,col ="darkgreen",add=T)
text(x = 0.3274354,y = 0.7076923,label="AUC:0.73",cex=1)

legend(x = "bottomright", 
       c('Test-NC:16,NS:27','Validation-NC:13,NS:19','NC:Number of control','NS:Number of steatosis'),lty=c(1,1),
       lwd=c(2,2),col=c('darkred','darkgreen','white','white'))


```


lets do the jitter plot for train and validation test.

```{r}

train_data_plot<-as.data.frame(train)

train_data_plot$sample=as.factor(train_data_plot$sample)

a<-compare_means(c(C9,HPRT1,TLR1,B2M,BAX,GAPDH,BTK,PTPN6,SERPING1,ITGAE,IL1RAP,MSR1,TNFRSF14,IL15,CX3CR1,TOLLIP,IFIH1,C4BPA) ~ sample ,data = train_data_plot)


```




```{r}

my_gene_list <- c("C9","HPRT1","TLR1","B2M","BAX","GAPDH","BTK","PTPN6","SERPING1","ITGAE","IL1RAP","MSR1","TNFRSF14","IL15","CX3CR1","TOLLIP","IFIH1","C4BPA")

 my_plot_list <- vector(mode = "list", length = 18)

for (i in 1:18) {
  my_comparisons <- list( c("Steatosis", "Control") )
  p <-ggboxplot(train_data_plot, x = "sample", y = my_gene_list[i],
          color = "sample", palette = "jco",add = "jitter")+
          stat_compare_means(label.y = 16)
  my_plot_list[[i]] <- p
}
 
print(my_plot_list[1:18])
```


## Validation Set


```{r}

validation_data_plot<-as.data.frame(validation)

validation_data_plot$sample=as.factor(validation_data_plot$sample)

compare_means(c(BTK,PTPN6,SERPING1,ITGAE,IL1RAP,MSR1,TNFRSF14,IL15,CX3CR1,TOLLIP,IFIH1,C4BPA) ~ sample ,data = validation_data_plot)

```


plot the bar graph for validation set 

```{r}

my_plot_list_2 <- vector(mode = "list", length = 18)

for (i in 1:18) {
  my_comparisons <- list( c("Steatosis", "Control") )
  p <-ggboxplot(validation_data_plot, x = "sample", y = my_gene_list[i],
          color = "sample", palette = "jco",add = "jitter")+
          stat_compare_means(label.y = 16)
  my_plot_list_2[[i]] <- p
}
 
print(my_plot_list_2[1:18])



```

## Enricher 

```{r}
setEnrichrSite("Enrichr") # Human genes

websiteLive <- TRUE

dbs <- listEnrichrDbs()

dbs <- c("GO_Molecular_Function_2021", "GO_Cellular_Component_2021", "GO_Biological_Process_2021",
         "Reactome_2021","KEGG_2021_Human")

```


```{r}

genes_name<-colnames(train)

genes_name<-genes_name[2:nrow(train)]

if (websiteLive) {
  enriched <- enrichr(genes_name, dbs)
}


```


```{r}
if (websiteLive) datatable(enriched[["KEGG_2021_Human"]])
```

```{r}

if (websiteLive) plotEnrich(enriched[[5]], showTerms = 20, numChar = 40, y = "Count", orderBy = "P.value",title = "Enrichment analysis")

```


make the correlation

```{r}

steatosis<-'steatosis'

steatosis_samples<-train[train$sample %in% steatosis, ]  

steatosis_samples<-steatosis_samples[,-c(1)]

steatosis_samples <- cor(steatosis_samples)

corrplot(steatosis_samples,method="circle",cl.lim=c(-1,1),col=colorRampPalette(c("blue","white","red"))(200))

```


```{r}

control<-'control'

control_samples<-train[train$sample %in% control, ]  

control_samples<-control_samples[,-c(1)]

control_samples <- cor(control_samples)

corrplot(control_samples,method="circle",cl.lim=c(-1,1),col=colorRampPalette(c("blue","white","red"))(200))

```


```{r}
sessionInfo()
```







